{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_info222 >>>> ['2', '4', '6', '7']\n",
      "step1 finished -------\n",
      "step2 finished -------\n",
      "step3 finished -------\n",
      "weather_df>>>>          date  mean_temp  mean_humidity  mean_pressure  rain\n",
      "0  2020-01-01        1.9           44.0         1021.0   0.0\n",
      "1  2020-01-02        4.1           53.1         1018.8   0.0\n",
      "2  2020-01-03        5.9           43.0         1015.5   0.0\n",
      "3  2020-01-04        5.5           34.8         1015.3   0.0\n",
      "4  2020-01-05        7.4           51.1         1020.6   0.0\n",
      "5  2020-01-06        7.8           89.4         1017.8  10.7\n",
      "6  2020-01-07       14.4           96.6         1003.8  26.3\n",
      "7_dataframe finished >>>>>\n",
      "event_info222 >>>> ['2', '4', '6', '7']\n",
      "step1 finished -------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\ai-forecast\\back_end\\future7_dataframe.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['promotion_flag'] = event_info_for_merge\n",
      "C:\\Users\\user\\ai-forecast\\back_end\\future7_dataframe.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['break'] = break_list_for_merge\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step2 finished -------\n",
      "step3 finished -------\n",
      "weather_df>>>>          date  mean_temp  mean_humidity  mean_pressure  rain\n",
      "0  2020-01-01        1.9           44.0         1021.0   0.0\n",
      "1  2020-01-02        4.1           53.1         1018.8   0.0\n",
      "2  2020-01-03        5.9           43.0         1015.5   0.0\n",
      "3  2020-01-04        5.5           34.8         1015.3   0.0\n",
      "4  2020-01-05        7.4           51.1         1020.6   0.0\n",
      "5  2020-01-06        7.8           89.4         1017.8  10.7\n",
      "6  2020-01-07       14.4           96.6         1003.8  26.3\n",
      "7_dataframe finished >>>>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\ai-forecast\\back_end\\future7_dataframe.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['promotion_flag'] = event_info_for_merge\n",
      "C:\\Users\\user\\ai-forecast\\back_end\\future7_dataframe.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['break'] = break_list_for_merge\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "%run testtrainer.py\n",
    "%run predictor.py\n",
    "%run future7_dataframe.py\n",
    "%run data.py\n",
    "%run modeling.py\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_index = pd.DataFrame(\n",
    "data=[[1, '백산수2.0L', 'promotion_flag_1_bac_2',\n",
    "'sale_qty_1_bac_2', '1_bac2.hdf5'],\n",
    "[1, '백산수500ml', 'promotion_flag_1_bac_5',\n",
    "'sale_qty_1_bac_5', '1_bac5.hdf5'],\n",
    "[1, '신라면멀티', 'promotion_flag_1_sin',\n",
    "'sale_qty_1_sin', '1_sin.hdf5'],\n",
    "[1, '안성탕면멀티', 'promotion_flag_1_ans',\n",
    "'sale_qty_1_ans', '1_ans.hdf5'],\n",
    "[1, '진라면멀티(순한맛)', 'promotion_flag_1_jin',\n",
    "'sale_qty_1_jin', '1_jin.hdf5'],\n",
    "[6, '백산수2.0L', 'promotion_flag_6_bac_2',\n",
    "'sale_qty_6_bac_2', '6_bac2.hdf5'],\n",
    "[6, '백산수500ml', 'promotion_flag_6_bac_5',\n",
    "'sale_qty_6_bac_5', '6_bac5.hdf5'],\n",
    "[6, '신라면멀티', 'promotion_flag_6_sin',\n",
    "'sale_qty_6_sin', '6_sin.hdf5'],\n",
    "[6, '안성탕면멀티', 'promotion_flag_6_ans',\n",
    "'sale_qty_6_ans', '6_ans.hdf5'],\n",
    "[6, '진라면멀티(순한맛)', 'promotion_flag_6_jin', 'sale_qty_6_jin', '6_jin.hdf5']],\n",
    "columns=['store', 'product', 'promotion', 'sale', 'weight'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "storeList=[1,6]\n",
    "productList = ['백산수2.0L','백산수500ml','신라면멀티','안성탕면멀티','진라면멀티(순한맛)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_data >>>> 2019-12-01\n",
      "pre_event_info >>>>>> {'1': 'false', '2': 'false', '3': 'true', '4': 'false', '5': 'true', '6': 'false', '7': 'false'}\n",
      "event_info >>>> ['3', '5']\n",
      "break_info >>>> 1\n",
      "store_info>>>  1\n",
      "event_info222 >>>> ['3', '5']\n",
      "step1 finished -------\n",
      "step2 finished -------\n",
      "step3 finished -------\n",
      "weather_df>>>>          date  mean_temp  mean_humidity  mean_pressure  rain\n",
      "0  2019-12-01        9.5           92.9         1011.1  33.3\n",
      "1  2019-12-02        6.6           53.8         1010.0   2.5\n",
      "2  2019-12-03        4.6           52.1         1017.1   0.0\n",
      "3  2019-12-04        7.2           50.5         1019.5   0.0\n",
      "4  2019-12-05        4.6           39.3         1023.4   0.0\n",
      "5  2019-12-06        0.2           25.8         1023.4   0.0\n",
      "6  2019-12-07        3.6           40.0         1019.2   0.0\n",
      "7_dataframe finished >>>>>\n",
      "training init\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\ai-forecast\\back_end\\future7_dataframe.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['promotion_flag'] = event_info_for_merge\n",
      "C:\\Users\\user\\ai-forecast\\back_end\\future7_dataframe.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['break'] = break_list_for_merge\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0810 - mse: 0.1619\n",
      "Epoch 00001: val_loss improved from inf to 0.02890, saving model to ./weight_test/1_bac2.hdf5\n",
      "23/23 [==============================] - 4s 193ms/step - loss: 0.0810 - mse: 0.1619 - val_loss: 0.0289 - val_mse: 0.0578\n",
      "Epoch 2/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0359 - mse: 0.0718\n",
      "Epoch 00002: val_loss improved from 0.02890 to 0.01443, saving model to ./weight_test/1_bac2.hdf5\n",
      "23/23 [==============================] - 4s 168ms/step - loss: 0.0359 - mse: 0.0718 - val_loss: 0.0144 - val_mse: 0.0289\n",
      "Epoch 3/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0267 - mse: 0.0533\n",
      "Epoch 00003: val_loss improved from 0.01443 to 0.01344, saving model to ./weight_test/1_bac2.hdf5\n",
      "23/23 [==============================] - 4s 171ms/step - loss: 0.0267 - mse: 0.0533 - val_loss: 0.0134 - val_mse: 0.0269\n",
      "Epoch 4/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0251 - mse: 0.0503\n",
      "Epoch 00004: val_loss improved from 0.01344 to 0.01223, saving model to ./weight_test/1_bac2.hdf5\n",
      "23/23 [==============================] - 4s 168ms/step - loss: 0.0251 - mse: 0.0503 - val_loss: 0.0122 - val_mse: 0.0245\n",
      "Epoch 5/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0245 - mse: 0.0490\n",
      "Epoch 00005: val_loss improved from 0.01223 to 0.01189, saving model to ./weight_test/1_bac2.hdf5\n",
      "23/23 [==============================] - 4s 168ms/step - loss: 0.0245 - mse: 0.0490 - val_loss: 0.0119 - val_mse: 0.0238\n",
      "Epoch 6/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0234 - mse: 0.0468\n",
      "Epoch 00006: val_loss improved from 0.01189 to 0.01140, saving model to ./weight_test/1_bac2.hdf5\n",
      "23/23 [==============================] - 4s 168ms/step - loss: 0.0234 - mse: 0.0468 - val_loss: 0.0114 - val_mse: 0.0228\n",
      "Epoch 7/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0225 - mse: 0.0450\n",
      "Epoch 00007: val_loss improved from 0.01140 to 0.01095, saving model to ./weight_test/1_bac2.hdf5\n",
      "23/23 [==============================] - 4s 169ms/step - loss: 0.0225 - mse: 0.0450 - val_loss: 0.0109 - val_mse: 0.0219\n",
      "Epoch 8/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0219 - mse: 0.0438\n",
      "Epoch 00008: val_loss improved from 0.01095 to 0.01053, saving model to ./weight_test/1_bac2.hdf5\n",
      "23/23 [==============================] - 4s 172ms/step - loss: 0.0219 - mse: 0.0438 - val_loss: 0.0105 - val_mse: 0.0211\n",
      "Epoch 9/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0208 - mse: 0.0417\n",
      "Epoch 00009: val_loss improved from 0.01053 to 0.01013, saving model to ./weight_test/1_bac2.hdf5\n",
      "23/23 [==============================] - 4s 170ms/step - loss: 0.0208 - mse: 0.0417 - val_loss: 0.0101 - val_mse: 0.0203\n",
      "Epoch 10/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0201 - mse: 0.0403\n",
      "Epoch 00010: val_loss improved from 0.01013 to 0.00967, saving model to ./weight_test/1_bac2.hdf5\n",
      "23/23 [==============================] - 4s 170ms/step - loss: 0.0201 - mse: 0.0403 - val_loss: 0.0097 - val_mse: 0.0193\n",
      "Epoch 11/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0196 - mse: 0.0392\n",
      "Epoch 00011: val_loss improved from 0.00967 to 0.00918, saving model to ./weight_test/1_bac2.hdf5\n",
      "23/23 [==============================] - 4s 170ms/step - loss: 0.0196 - mse: 0.0392 - val_loss: 0.0092 - val_mse: 0.0184\n",
      "Epoch 12/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0193 - mse: 0.0385\n",
      "Epoch 00012: val_loss improved from 0.00918 to 0.00883, saving model to ./weight_test/1_bac2.hdf5\n",
      "23/23 [==============================] - 4s 171ms/step - loss: 0.0193 - mse: 0.0385 - val_loss: 0.0088 - val_mse: 0.0177\n",
      "Epoch 13/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0185 - mse: 0.0369\n",
      "Epoch 00013: val_loss did not improve from 0.00883\n",
      "23/23 [==============================] - 4s 168ms/step - loss: 0.0185 - mse: 0.0369 - val_loss: 0.0089 - val_mse: 0.0177\n",
      "Epoch 14/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0180 - mse: 0.0359\n",
      "Epoch 00014: val_loss improved from 0.00883 to 0.00821, saving model to ./weight_test/1_bac2.hdf5\n",
      "23/23 [==============================] - 5s 206ms/step - loss: 0.0180 - mse: 0.0359 - val_loss: 0.0082 - val_mse: 0.0164\n",
      "Epoch 15/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0177 - mse: 0.0354\n",
      "Epoch 00015: val_loss improved from 0.00821 to 0.00785, saving model to ./weight_test/1_bac2.hdf5\n",
      "23/23 [==============================] - 4s 194ms/step - loss: 0.0177 - mse: 0.0354 - val_loss: 0.0078 - val_mse: 0.0157\n",
      "Epoch 16/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0172 - mse: 0.0344\n",
      "Epoch 00016: val_loss did not improve from 0.00785\n",
      "23/23 [==============================] - 4s 173ms/step - loss: 0.0172 - mse: 0.0344 - val_loss: 0.0080 - val_mse: 0.0159\n",
      "Epoch 17/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0170 - mse: 0.0340\n",
      "Epoch 00017: val_loss did not improve from 0.00785\n",
      "23/23 [==============================] - 4s 172ms/step - loss: 0.0170 - mse: 0.0340 - val_loss: 0.0079 - val_mse: 0.0157\n",
      "Epoch 18/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0166 - mse: 0.0332\n",
      "Epoch 00018: val_loss improved from 0.00785 to 0.00776, saving model to ./weight_test/1_bac2.hdf5\n",
      "23/23 [==============================] - 4s 171ms/step - loss: 0.0166 - mse: 0.0332 - val_loss: 0.0078 - val_mse: 0.0155\n",
      "Epoch 19/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0162 - mse: 0.0325\n",
      "Epoch 00019: val_loss improved from 0.00776 to 0.00762, saving model to ./weight_test/1_bac2.hdf5\n",
      "23/23 [==============================] - 4s 173ms/step - loss: 0.0162 - mse: 0.0325 - val_loss: 0.0076 - val_mse: 0.0152\n",
      "Epoch 20/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0162 - mse: 0.0325\n",
      "Epoch 00020: val_loss improved from 0.00762 to 0.00737, saving model to ./weight_test/1_bac2.hdf5\n",
      "23/23 [==============================] - 4s 174ms/step - loss: 0.0162 - mse: 0.0325 - val_loss: 0.0074 - val_mse: 0.0147\n",
      "Epoch 21/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0165 - mse: 0.0329\n",
      "Epoch 00021: val_loss did not improve from 0.00737\n",
      "23/23 [==============================] - 4s 172ms/step - loss: 0.0165 - mse: 0.0329 - val_loss: 0.0077 - val_mse: 0.0153\n",
      "Epoch 22/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0156 - mse: 0.0311\n",
      "Epoch 00022: val_loss did not improve from 0.00737\n",
      "23/23 [==============================] - 4s 166ms/step - loss: 0.0156 - mse: 0.0311 - val_loss: 0.0080 - val_mse: 0.0161\n",
      "Epoch 23/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0155 - mse: 0.0309\n",
      "Epoch 00023: val_loss did not improve from 0.00737\n",
      "23/23 [==============================] - 4s 174ms/step - loss: 0.0155 - mse: 0.0309 - val_loss: 0.0078 - val_mse: 0.0155\n",
      "Epoch 24/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0150 - mse: 0.0300\n",
      "Epoch 00024: val_loss did not improve from 0.00737\n",
      "23/23 [==============================] - 4s 174ms/step - loss: 0.0150 - mse: 0.0300 - val_loss: 0.0079 - val_mse: 0.0159\n",
      "Epoch 25/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0148 - mse: 0.0296\n",
      "Epoch 00025: val_loss did not improve from 0.00737\n",
      "23/23 [==============================] - 4s 183ms/step - loss: 0.0148 - mse: 0.0296 - val_loss: 0.0077 - val_mse: 0.0154\n",
      "Epoch 26/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0150 - mse: 0.0300\n",
      "Epoch 00026: val_loss improved from 0.00737 to 0.00696, saving model to ./weight_test/1_bac2.hdf5\n",
      "23/23 [==============================] - 4s 192ms/step - loss: 0.0150 - mse: 0.0300 - val_loss: 0.0070 - val_mse: 0.0139\n",
      "Epoch 27/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0157 - mse: 0.0315\n",
      "Epoch 00027: val_loss did not improve from 0.00696\n",
      "23/23 [==============================] - 4s 186ms/step - loss: 0.0157 - mse: 0.0315 - val_loss: 0.0076 - val_mse: 0.0152\n",
      "Epoch 28/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0148 - mse: 0.0296\n",
      "Epoch 00028: val_loss did not improve from 0.00696\n",
      "23/23 [==============================] - 5s 201ms/step - loss: 0.0148 - mse: 0.0296 - val_loss: 0.0080 - val_mse: 0.0161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0144 - mse: 0.0288\n",
      "Epoch 00029: val_loss did not improve from 0.00696\n",
      "23/23 [==============================] - 4s 180ms/step - loss: 0.0144 - mse: 0.0288 - val_loss: 0.0088 - val_mse: 0.0176\n",
      "Epoch 30/2000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0141 - mse: 0.0283\n",
      "Epoch 00030: val_loss did not improve from 0.00696\n",
      "23/23 [==============================] - 4s 167ms/step - loss: 0.0141 - mse: 0.0283 - val_loss: 0.0084 - val_mse: 0.0169\n",
      "Epoch 31/2000\n",
      " 5/23 [=====>........................] - ETA: 2s - loss: 0.0216 - mse: 0.0432"
     ]
    }
   ],
   "source": [
    "\n",
    "# from future7_dataframe import date_info, row_select\n",
    "\n",
    "# from predictor import predictor\n",
    "\n",
    "# from matplotlib import pyplot\n",
    "\n",
    "# from testtrainer import start_train\n",
    "\n",
    "for storeOne in storeList:\n",
    "    for productOne in productList:\n",
    "\n",
    "        start_date = '2019-12-01'\n",
    "        print('start_data >>>>', start_date)\n",
    "\n",
    "        #     할인정보 시작\n",
    "        pre_event_info = {'1': 'false', '2': 'false', '3': 'true', '4': 'false', '5': 'true', '6': 'false', '7': 'false'}\n",
    "        print('pre_event_info >>>>>>', pre_event_info)\n",
    "\n",
    "        event_info = []\n",
    "        for i in pre_event_info.keys():\n",
    "\n",
    "            if pre_event_info[i] == 'true':\n",
    "                event_info.append(i)\n",
    "\n",
    "        print('event_info >>>>', event_info)\n",
    "        #     할인정보 끝\n",
    "\n",
    "        break_info = 1\n",
    "        store_info = storeOne\n",
    "\n",
    "        print('break_info >>>>', break_info)\n",
    "        print('store_info>>> ', store_info)\n",
    "\n",
    "        product_info = productOne\n",
    "\n",
    "        merged_df = date_info(start_date, event_info, break_info)\n",
    "\n",
    "        startdt = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "\n",
    "        train_subtracttime = timedelta(days=1)\n",
    "\n",
    "        train_date = startdt - train_subtracttime\n",
    "\n",
    "        train_date = train_date.strftime('%Y-%m-%d')\n",
    "\n",
    "        predict_addtime = timedelta(days=6)\n",
    "\n",
    "        predict_date = startdt + predict_addtime\n",
    "\n",
    "        predict_date = predict_date.strftime('%Y-%m-%d')\n",
    "        print(\"training init\")\n",
    "\n",
    "        ready_train = start_train(merged_df, int(store_info), product_info, train_date,\n",
    "                                  predict_date)\n",
    "\n",
    "        history = ready_train.trainer()\n",
    "\n",
    "\n",
    "\n",
    "        product_name=product_info\n",
    "        store_code=store_info\n",
    "\n",
    "        model_name = meta_index[(meta_index['store'] == store_code) & (\n",
    "        meta_index['product'] == product_name)].iloc[0]['weight']\n",
    "\n",
    "        df, df_train, df_test, sale_qty, x_columns, x_1_columns = data.sep_data2(train='AI_Sale_ver4.0.csv', test=merged_df,\n",
    "                                                                                         product_name=product_name,\n",
    "                                                                                         store_code=store_code,\n",
    "                                                                                         train_date=train_date,\n",
    "                                                                                         predict_date=predict_date)\n",
    "\n",
    "        (x_scaler, x_1_scaler, y_scaler, column_num_x, column_num_x_1,\n",
    "         x_columns, x_1_columns, sale_qty) = data.scaled_origin(sequence_x=sequence_x,\n",
    "                                                                sequence_y=sequence_y,\n",
    "                                                                product_name=product_name,\n",
    "                                                                store_code=store_code)\n",
    "\n",
    "        x_train_scaled, x_train_1_scaled, y_train_scaled = data.scaled_data(sequence_x=sequence_x,\n",
    "                                                                            sequence_y=sequence_y,\n",
    "                                                                            df_train=df_train,\n",
    "                                                                            product_name=product_name,\n",
    "                                                                            store_code=store_code\n",
    "                                                                            )\n",
    "        x_test_scaled, x_test_1_scaled, y_test_scaled = data.scaled_data(sequence_x=sequence_x,\n",
    "                                                                            sequence_y=sequence_y,\n",
    "                                                                            df_train=df_test,\n",
    "                                                                            product_name=product_name,\n",
    "                                                                            store_code=store_code\n",
    "                                                                            )\n",
    "\n",
    "\n",
    "        callback_path = './weight_test/'+model_name\n",
    "        \n",
    "        model = create_model(\n",
    "                    column_num_x, column_num_x_1, sequence_x, sequence_y)\n",
    "        model.load_weights(callback_path)\n",
    "\n",
    "        y_test_predict = model.predict(x=(x_test_scaled,x_test_1_scaled))#,batch_size=1)\n",
    "\n",
    "        y_test_scaled=np.reshape(y_test_scaled,(y_test_scaled.shape[0],y_test_scaled.shape[1]))\n",
    "\n",
    "        y_test_predict=np.reshape(y_test_predict,(y_test_predict.shape[0],y_test_predict.shape[1]))\n",
    "\n",
    "        y_test_in = y_scaler.inverse_transform(y_test_scaled)\n",
    "        y_test_pre_in = y_scaler.inverse_transform(y_test_predict)\n",
    "\n",
    "\n",
    "        # import matplotlib.pyplot\n",
    "\n",
    "        for i in np.arange(957,958):\n",
    "            plt.figure(figsize=(7,7))\n",
    "            j=0\n",
    "            period = np.arange(0+j,7+j)\n",
    "            plt.plot(period,y_test_in[i], 'ro-', label=\"real\")\n",
    "            plt.plot(period,y_test_pre_in[i], 'ys-', label=\"predicted\")\n",
    "            j+=1\n",
    "        # plt.plot(result_list2, 'go-', label=\"predicted2\")\n",
    "            plt.legend()\n",
    "            plt.title((j))\n",
    "            plt.savefig('./graph_image/'+model_name+'비교.png')\n",
    "\n",
    "        y_test_in[-1]\n",
    "\n",
    "        y_test_pre_in[-1]\n",
    "\n",
    "        plt.plot(history.history['loss'], label='train')\n",
    "        plt.plot(history.history['val_loss'], label='validation')\n",
    "        plt.legend()\n",
    "        plt.savefig('./graph_image/'+model_name+'학습.png')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
